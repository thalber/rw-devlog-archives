JLJac
78

Awesome! Thank you, Jimbert <img src="https://web.archive.org/web/20141229083417im_/http://forums.tigsource.com/Smileys/derek/grin.gif" alt="Grin" border="0"> My implementation is actually very similar to those gradient maps, except my input is ... what would it be, 7 dimensional, and the output is a coordinate on a 2D palette texture rather than an 1-dimensional gradient.<br><br>I&#039;ve had pretty good luck today, and got quite far with my deciphering algorithm! Then I ran into a weird error. I hit my instruction limit, which was kind of due to happen because the basic settings only allow for 64 instructions.<br><br>No biggie, let&#039;s just upgrade to shader model 3.0, right? That&#039;s like, 2003 graphic cards or something, people&#039;s PC&#039;s will be able to handle that.<br><br>No can do. For some reason Unity says &quot;no subshaders can run at this graphics card&quot; if I target the shader at anything higher than 2.0. Unity refuses to believe anything else than that my graphics card is from 2002. <br><br>I&#039;ve searched Unity&#039;s settings for the &quot;dude I bought my computer 2 months ago it&#039;s not ten years old&quot;-checkbox, but can&#039;t seem to find it. There&#039;s an option to <i>emulate </i>for 3.0, in order to try the compability with older machines, but since Unity is adamant that my machine is even older than those older machines, no luck.<br><br>Any tips?<br><br>Found a command SystemInfo.graphicsShaderLevel in Unity, and this claims that I have 3.0, which is worrying for every reason. First, if I have 3.0 it <i>should</i> work, right? Second, I <i>don&#039;t</i> have 3.0, I&#039;m supposed to have 5.0! Fun times! 