JLJac
262

Dude, you don&#039;t even want to know. I&#039;ve fallen into a programming habit where I have basically everything as floats between 0 and 1 and use lerps within lerps within lerps, and pows, so many pows. Because pow has a really nice effect on a 0&lt;=f&lt;=1 float, being that it sort of shits the value upwards or downwards (exponent below or above 1) whilst keeping the edge cases 0 and 1 in the same places. So then I can change the tendency of a value, but still know where I have my edge cases, like so:<br><br>if(Random.value &lt; Mathf.pow(anger, Mathf.lerp(1.5f, 0.3f, personality.mean)))<br>&nbsp; &nbsp; Attack();<br><br>In the above case the chance of attacking will always be 0% if anger is 0, and always be 100% if anger is 1, but in the cases in-between the curve is skewed depending on the personality.mean variable. I love it, and it has soooooooo many floating point exponents&nbsp; <img src="https://web.archive.org/web/20210308165327im_/https://forums.tigsource.com/Smileys/derek/wtf.gif" alt="WTF" border="0"><br><br>And... this has of course leaked into my shader code as well. So, yeah, thanks for the heads up. Might need to go in there and clean a bit of that up if it&#039;s a big problem. I haven&#039;t noticed any performance issues with it though, neither in the c# or the shaders. Admittedly haven&#039;t tried on a lot of computers, so the problem might surface during beta testing - but we have run it on a few computers including a weak laptop and haven&#039;t had any issues so far. 